{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f3dc04-c473-4287-85cb-9e1f5809d3e5",
   "metadata": {},
   "source": [
    "# Project 17 - Winning Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2b404-fd43-4062-8ead-99f1f9678f70",
   "metadata": {},
   "source": [
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. In this project we will work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win. You can find the dataset [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6598bf9-c28f-457a-96b4-d38696b28f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>$200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>$200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>RIDDLE ME THIS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'This Puccini opera turns on the solution to 3...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Turandot</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>\"T\" BIRDS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In North America this term is properly applie...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>a titmouse</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>AUTHORS IN THEIR YOUTH</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'In Penny Lane, where this \"Hellraiser\" grew u...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Clive Barker</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>QUOTATIONS</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'From Ft. Sill, Okla. he made the plea, Arizon...</td>\n",
       "      <td>$2000</td>\n",
       "      <td>Geronimo</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>HISTORIC NAMES</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>'A silent movie title includes the last name o...</td>\n",
       "      <td>None</td>\n",
       "      <td>Grigori Alexandrovich Potemkin</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216930 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               category    air_date  \\\n",
       "0                               HISTORY  2004-12-31   \n",
       "1       ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "2           EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "3                      THE COMPANY LINE  2004-12-31   \n",
       "4                   EPITAPHS & TRIBUTES  2004-12-31   \n",
       "...                                 ...         ...   \n",
       "216925                   RIDDLE ME THIS  2006-05-11   \n",
       "216926                        \"T\" BIRDS  2006-05-11   \n",
       "216927           AUTHORS IN THEIR YOUTH  2006-05-11   \n",
       "216928                       QUOTATIONS  2006-05-11   \n",
       "216929                   HISTORIC NAMES  2006-05-11   \n",
       "\n",
       "                                                 question  value  \\\n",
       "0       'For the last 8 years of his life, Galileo was...   $200   \n",
       "1       'No. 2: 1912 Olympian; football star at Carlis...   $200   \n",
       "2       'The city of Yuma in this state has a record a...   $200   \n",
       "3       'In 1963, live on \"The Art Linkletter Show\", t...   $200   \n",
       "4       'Signer of the Dec. of Indep., framer of the C...   $200   \n",
       "...                                                   ...    ...   \n",
       "216925  'This Puccini opera turns on the solution to 3...  $2000   \n",
       "216926  'In North America this term is properly applie...  $2000   \n",
       "216927  'In Penny Lane, where this \"Hellraiser\" grew u...  $2000   \n",
       "216928  'From Ft. Sill, Okla. he made the plea, Arizon...  $2000   \n",
       "216929  'A silent movie title includes the last name o...   None   \n",
       "\n",
       "                                answer             round  show_number  \n",
       "0                           Copernicus         Jeopardy!         4680  \n",
       "1                           Jim Thorpe         Jeopardy!         4680  \n",
       "2                              Arizona         Jeopardy!         4680  \n",
       "3                          McDonald\\'s         Jeopardy!         4680  \n",
       "4                           John Adams         Jeopardy!         4680  \n",
       "...                                ...               ...          ...  \n",
       "216925                        Turandot  Double Jeopardy!         4999  \n",
       "216926                      a titmouse  Double Jeopardy!         4999  \n",
       "216927                    Clive Barker  Double Jeopardy!         4999  \n",
       "216928                        Geronimo  Double Jeopardy!         4999  \n",
       "216929  Grigori Alexandrovich Potemkin   Final Jeopardy!         4999  \n",
       "\n",
       "[216930 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json('JEOPARDY_QUESTIONS1.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b335f-d2c8-4454-af39-551cecf0a3f2",
   "metadata": {},
   "source": [
    "From the table above we can see that our data has 216930 rows and 7 columns. The columns are:\n",
    "- `category` - the category of the question\n",
    "- `air_date` - the date the episode aired\n",
    "- `question` - the text of the question\n",
    "- `value` - the number of dollars the correct answer is worth\n",
    "- `answer` - the text of the correct answer\n",
    "- `round` - the round of Jeopardy\n",
    "- `show_number` - the Jeopardy episode number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff172673-dbd8-4529-b5d7-90880f9b0698",
   "metadata": {},
   "source": [
    "## Normalizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a196a8b-ed98-4af8-a746-867e818f7054",
   "metadata": {},
   "source": [
    "Before we begin our analysis, we need to normalize the text, meaning that we are going to lower all the text columns (for example `Don't` is not the same as `don't`, so we want all the letters lower case). We also want to remove all the punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af26fa98-5a94-49eb-8e0b-a8b94920d443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these two should look the same\n",
      "these two should look the same \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"\\W\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "#testing\n",
    "print(\"these two should look the same\")\n",
    "print(normalize_text(\"THese,, two ShoUld loOk!! The same,..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08641912-9b8c-4eba-9d59-894bc6e55133",
   "metadata": {},
   "source": [
    "Now we can normalize the `question` and `answer` columns with our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8660c531-48d2-467a-bd02-65639f368ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>for the last 8 years of his life galileo was ...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle ...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>the city of yuma in this state has a record a...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>$200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>in 1963 live on the art linkletter show this ...</td>\n",
       "      <td>mcdonald s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>$200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>signer of the dec of indep framer of the cons...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category    air_date  \\\n",
       "0                          HISTORY  2004-12-31   \n",
       "1  ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "2      EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "3                 THE COMPANY LINE  2004-12-31   \n",
       "4              EPITAPHS & TRIBUTES  2004-12-31   \n",
       "\n",
       "                                            question value       answer  \\\n",
       "0  'For the last 8 years of his life, Galileo was...  $200   Copernicus   \n",
       "1  'No. 2: 1912 Olympian; football star at Carlis...  $200   Jim Thorpe   \n",
       "2  'The city of Yuma in this state has a record a...  $200      Arizona   \n",
       "3  'In 1963, live on \"The Art Linkletter Show\", t...  $200  McDonald\\'s   \n",
       "4  'Signer of the Dec. of Indep., framer of the C...  $200   John Adams   \n",
       "\n",
       "       round  show_number                                     clean_question  \\\n",
       "0  Jeopardy!         4680   for the last 8 years of his life galileo was ...   \n",
       "1  Jeopardy!         4680   no 2 1912 olympian football star at carlisle ...   \n",
       "2  Jeopardy!         4680   the city of yuma in this state has a record a...   \n",
       "3  Jeopardy!         4680   in 1963 live on the art linkletter show this ...   \n",
       "4  Jeopardy!         4680   signer of the dec of indep framer of the cons...   \n",
       "\n",
       "  clean_answer  \n",
       "0   copernicus  \n",
       "1   jim thorpe  \n",
       "2      arizona  \n",
       "3   mcdonald s  \n",
       "4   john adams  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,'clean_question'] = data['question'].apply(normalize_text)\n",
    "data.loc[:,'clean_answer'] = data['answer'].apply(normalize_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcaa122-3250-41c7-a113-314344d2cc01",
   "metadata": {},
   "source": [
    "## Normalizing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46537723-2df8-4224-b338-0fb6ab376a42",
   "metadata": {},
   "source": [
    "We also want to normalize `value` column by deleting the dollar sign, and normalize `air_date` column from string to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145c5b3e-f89f-42aa-b512-e4f736ddaec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "def normalize_value(value):\n",
    "    '''\n",
    "    return value without punctuations and dollar sign\n",
    "    return 0 if errors\n",
    "    '''\n",
    "    value = re.sub('\\W', \"\", value)\n",
    "    try:\n",
    "        value = int(value)\n",
    "    except Exception:\n",
    "        value = 0\n",
    "    return value\n",
    "        \n",
    "#test\n",
    "print(normalize_value(\"$200,000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b300dae-34d2-4434-8728-ae8c81fe7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing value column\n",
    "data['value'] = data['value'].astype('str')\n",
    "data['clean_value'] = data['value'].apply(normalize_value)\n",
    "\n",
    "#normalizing date column\n",
    "data['air_date'] = pd.to_datetime(data['air_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4020573d-1d54-4774-a0a9-7f899cbe4ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>for the last 8 years of his life galileo was ...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle ...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>the city of yuma in this state has a record a...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>$200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>in 1963 live on the art linkletter show this ...</td>\n",
       "      <td>mcdonald s</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>$200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "      <td>signer of the dec of indep framer of the cons...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category   air_date  \\\n",
       "0                          HISTORY 2004-12-31   \n",
       "1  ESPN's TOP 10 ALL-TIME ATHLETES 2004-12-31   \n",
       "2      EVERYBODY TALKS ABOUT IT... 2004-12-31   \n",
       "3                 THE COMPANY LINE 2004-12-31   \n",
       "4              EPITAPHS & TRIBUTES 2004-12-31   \n",
       "\n",
       "                                            question value       answer  \\\n",
       "0  'For the last 8 years of his life, Galileo was...  $200   Copernicus   \n",
       "1  'No. 2: 1912 Olympian; football star at Carlis...  $200   Jim Thorpe   \n",
       "2  'The city of Yuma in this state has a record a...  $200      Arizona   \n",
       "3  'In 1963, live on \"The Art Linkletter Show\", t...  $200  McDonald\\'s   \n",
       "4  'Signer of the Dec. of Indep., framer of the C...  $200   John Adams   \n",
       "\n",
       "       round  show_number                                     clean_question  \\\n",
       "0  Jeopardy!         4680   for the last 8 years of his life galileo was ...   \n",
       "1  Jeopardy!         4680   no 2 1912 olympian football star at carlisle ...   \n",
       "2  Jeopardy!         4680   the city of yuma in this state has a record a...   \n",
       "3  Jeopardy!         4680   in 1963 live on the art linkletter show this ...   \n",
       "4  Jeopardy!         4680   signer of the dec of indep framer of the cons...   \n",
       "\n",
       "  clean_answer  clean_value  \n",
       "0   copernicus          200  \n",
       "1   jim thorpe          200  \n",
       "2      arizona          200  \n",
       "3   mcdonald s          200  \n",
       "4   john adams          200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f71c6d-c98f-4d9b-9217-de9c7aa7f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category                  object\n",
       "air_date          datetime64[ns]\n",
       "question                  object\n",
       "value                     object\n",
       "answer                    object\n",
       "round                     object\n",
       "show_number                int64\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32da973-52f1-4621-b261-8dae4b546cf6",
   "metadata": {},
   "source": [
    "The table above shows that we have `int` values for `clean_value` and datetime for `air_date`. Next we are going to find out is it smart to study past questions, general knowledge, or not study at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0fc0d8-53cc-403c-b825-0b33f08cf4c2",
   "metadata": {},
   "source": [
    "## Answers in Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c39423-a88b-469f-a515-cc699e24ee11",
   "metadata": {},
   "source": [
    "In order to figure out whether to study past questions, study general knowledge, or not study at all, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer can be used for a question.\n",
    "- How often questions are repeated.\n",
    "\n",
    "If questions are repeated, they probably aren't repeated exactly the same (words could be different for example, options could be different etc.). Because of this, we are going to write a function that checks how often complex words (over 6 characters) reoccur. For example for the question in row number 3: `in 1963 live on the art linkletter show this...`, we can check how often the word `linkletter` reoccurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38539bf8-3a89-44ec-857f-2dfc8dca832b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06141691161144138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_in_question(row):\n",
    "    '''\n",
    "    this function check how many times terms in clean_answer occur in clean_question\n",
    "    '''\n",
    "    match_count = 0\n",
    "    #splitting questions and answers to a list of words\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    #remove \"the\" from the list\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    #prevents dividing by 0 later\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    #checks if the answer is in the question\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count += 1\n",
    "    return match_count/len(split_answer)\n",
    "\n",
    "data['answer_in_question'] = data.apply(answer_in_question, axis=1)\n",
    "mean_answer_in_question = data['answer_in_question'].mean()\n",
    "mean_answer_in_question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd45ed7-4964-48e9-8c00-e0e905cb6e69",
   "metadata": {},
   "source": [
    "Above we created a function that checks if the answer can be found from the question. On average, the answer only makes up for about 6% of the question. We shouldn't hope that hearing the question makes us able to determine the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68722b5c-dee6-44d3-bbae-5d7624eb7980",
   "metadata": {},
   "source": [
    "## Recycled Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aecf96-2dc0-4005-96ff-af6108f2ce24",
   "metadata": {},
   "source": [
    "Let's now find out how often new questions repeat the older ones in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d7dbcb-f651-40b0-9774-c365ded798c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10_j_05a', 'toppler', 'javier', 'sinning', 'mauritius', 'durrell', 'kaside', 'huxtables', 'saucer', 'voorhees']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9003767772153685"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "#sorting dates to start from 1984\n",
    "data.sort_values('air_date', ascending=True)\n",
    "#looping each row\n",
    "for index, row in data.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    ### remove words with less than 6 characters\n",
    "    split_question = [word for word in split_question if len(word) > 5]\n",
    "    match_count = 0\n",
    "    #checks if words are in terms_used\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    #add words to terms_used\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    #calculate match_count per words used\n",
    "    if len(split_question) > 0:\n",
    "        match_count = match_count/len(split_question)\n",
    "    question_overlap.append(match_count) \n",
    "    \n",
    "#question overlaps to column\n",
    "data['question_overlap'] = question_overlap\n",
    "\n",
    "#set to list just to show some example values\n",
    "set_to_list = list(terms_used)\n",
    "print(set_to_list[:10])\n",
    "\n",
    "question_overlap_mean = data['question_overlap'].mean()\n",
    "question_overlap_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44911024-899b-435a-8913-03ff206b783a",
   "metadata": {},
   "source": [
    "Above we can see example of the values in our set, meaning words that are over 6 characters long. `Question overlap mean` is very high, over 90%. This means that most of the questions are recycled. This also increases over time: \n",
    "- first 20000 rows: around 72%\n",
    "- first 50000 rows: around 81%\n",
    "- first 100000 rows: around 86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96dde46b-2d7a-456b-909d-be46355f46c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.723582840725705\n",
      "0.8104615722460577\n",
      "0.8600331081817143\n"
     ]
    }
   ],
   "source": [
    "first_20000_mean = data['question_overlap'][:20000].mean()\n",
    "first_50000_mean = data['question_overlap'][:50000].mean()\n",
    "first_100000_mean = data['question_overlap'][:100000].mean()\n",
    "\n",
    "print(first_20000_mean)\n",
    "print(first_50000_mean)\n",
    "print(first_100000_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996a3ed-18f8-485c-9661-20bf9f7678e6",
   "metadata": {},
   "source": [
    "However, our code only looks at single terms. It doesn't necessarily mean that the question is exactly the same, for example:\n",
    "- When was Crash Bandicoot published?\n",
    "- How many players have played Crash Bandicoot?\n",
    "  \n",
    "Both of these questions contain term `Bandicoot` which would make them overlap, yet the question is completely different. It could still be beneficial to study about the questions that overlap the most, if you know everything about `Bandicoot`, you could answer both of these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376b626-d18a-4c86-bc72-cd8dc7321954",
   "metadata": {},
   "source": [
    "## Low Value vs High Value Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638a8f1b-0d16-4107-bbd9-10a4323ebcdc",
   "metadata": {},
   "source": [
    "Next we are going to find out which terms correspond to high-value questions using a chi-squared test. Let's make two categories:\n",
    "- Low value: value is less (or equal) than 800\n",
    "- High value: value is more than 800\n",
    "\n",
    "We will create a function to find out the amount of low and high value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "682ba2d3-227e-4dac-96d8-a97f10509778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>answer_in_question</th>\n",
       "      <th>question_overlap</th>\n",
       "      <th>high_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169784</th>\n",
       "      <td>THE PERFECT GIFT</td>\n",
       "      <td>1998-12-23</td>\n",
       "      <td>'This greeting card company operates \"Gold Cro...</td>\n",
       "      <td>$100</td>\n",
       "      <td>Hallmark</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>3293</td>\n",
       "      <td>this greeting card company operates gold crow...</td>\n",
       "      <td>hallmark</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172622</th>\n",
       "      <td>\"FI\"</td>\n",
       "      <td>1999-04-21</td>\n",
       "      <td>'The basic pitch of this small flute is usuall...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Fife</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>3378</td>\n",
       "      <td>the basic pitch of this small flute is usuall...</td>\n",
       "      <td>fife</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104290</th>\n",
       "      <td>18TH CENTURY AMERICA</td>\n",
       "      <td>2007-11-02</td>\n",
       "      <td>'Samuel Slater settled in R.I. &amp; built America...</td>\n",
       "      <td>$1600</td>\n",
       "      <td>water power</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>5325</td>\n",
       "      <td>samuel slater settled in r i built america s ...</td>\n",
       "      <td>water power</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category   air_date  \\\n",
       "169784      THE PERFECT GIFT 1998-12-23   \n",
       "172622                  \"FI\" 1999-04-21   \n",
       "104290  18TH CENTURY AMERICA 2007-11-02   \n",
       "\n",
       "                                                 question  value       answer  \\\n",
       "169784  'This greeting card company operates \"Gold Cro...   $100     Hallmark   \n",
       "172622  'The basic pitch of this small flute is usuall...   $200         Fife   \n",
       "104290  'Samuel Slater settled in R.I. & built America...  $1600  water power   \n",
       "\n",
       "                   round  show_number  \\\n",
       "169784         Jeopardy!         3293   \n",
       "172622  Double Jeopardy!         3378   \n",
       "104290  Double Jeopardy!         5325   \n",
       "\n",
       "                                           clean_question clean_answer  \\\n",
       "169784   this greeting card company operates gold crow...     hallmark   \n",
       "172622   the basic pitch of this small flute is usuall...         fife   \n",
       "104290   samuel slater settled in r i built america s ...  water power   \n",
       "\n",
       "        clean_value  answer_in_question  question_overlap  high_value  \n",
       "169784          100                 0.0               1.0           0  \n",
       "172622          200                 0.0               1.0           0  \n",
       "104290         1600                 0.5               1.0           1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value_finder(value):\n",
    "    if value > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "data['high_value'] = data['clean_value'].apply(value_finder)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4493b9d-0f89-412d-b639-5fc3391be042",
   "metadata": {},
   "source": [
    "Next we will create a function that finds the terms used in low and high value questions. We will choose 10 words from `terms_used` to test our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe98eaa-cda1-4313-863d-86bb30ba6145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10_j_05a', 'toppler', 'javier', 'sinning', 'mauritius', 'durrell', 'kaside', 'huxtables', 'saucer', 'voorhees']\n",
      "[(1, 0), (0, 1), (6, 8), (2, 4), (3, 13), (0, 3), (0, 1), (0, 2), (1, 5), (0, 3)]\n"
     ]
    }
   ],
   "source": [
    "def term_counter(text):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in data.iterrows():\n",
    "        split_question = row['clean_question'].split(\" \")\n",
    "        if text in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "#10 words from the set terms_used (picked earlier)\n",
    "comparison_terms = set_to_list[:10]\n",
    "print(comparison_terms)\n",
    "\n",
    "observed_expected = []\n",
    "for term in comparison_terms:\n",
    "    term_counts =term_counter(term)\n",
    "    observed_expected.append(term_counts)\n",
    "\n",
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa28b6-872b-4d6b-8c59-f85a9b0f6087",
   "metadata": {},
   "source": [
    "From above we can see 10 different words and their counts on high value and low value questions. For example the word `javier` shows up 6 times in high value questions, and 8 times in low value questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc2405-3c29-450a-ab6c-2d28127aecbc",
   "metadata": {},
   "source": [
    "## Applying the Chi-squared Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56860ca-55b1-4c2d-9ba1-9a810d32d206",
   "metadata": {},
   "source": [
    "Above we calculated only the observed values for 10 different terms. To use Chi-squared test, we also have to find expected values. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778b0e58-e7c2-4269-a13d-1c2ef0df22d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61422\n",
      "155508\n"
     ]
    }
   ],
   "source": [
    "high_value_count = data[data['high_value'] == 1].shape[0]\n",
    "low_value_count = data[data['high_value'] == 0].shape[0] \n",
    "print(high_value_count)\n",
    "print(low_value_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98bfde-0a76-442e-aaa6-5e2ac8eeca50",
   "metadata": {},
   "source": [
    "Our dataset has 61422 high value questions and 155508 low value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afbed527-7488-45fb-a3de-622b69aa55cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=2.5317964247338085, pvalue=0.11157312838169751),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=1.4587975000965432, pvalue=0.2271215479927517),\n",
       " Power_divergenceResult(statistic=0.07446818777814278, pvalue=0.7849388502668134),\n",
       " Power_divergenceResult(statistic=0.7210743923775407, pvalue=0.395791714978203),\n",
       " Power_divergenceResult(statistic=1.184929392700054, pvalue=0.27635474913315955),\n",
       " Power_divergenceResult(statistic=0.3949764642333513, pvalue=0.5296950912486695),\n",
       " Power_divergenceResult(statistic=0.7899529284667026, pvalue=0.3741143592744989),\n",
       " Power_divergenceResult(statistic=0.4010346717612653, pvalue=0.5265553925560025),\n",
       " Power_divergenceResult(statistic=1.184929392700054, pvalue=0.27635474913315955)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "chi_squared = []\n",
    "for list in observed_expected:\n",
    "    total = list[0] + list[1]\n",
    "    total_prop = total/data.shape[0]\n",
    "    expected_high = total_prop*high_value_count\n",
    "    expected_low = total_prop*low_value_count\n",
    "\n",
    "    observed = np.array([list[0], list[1]])\n",
    "    expected = np.array([expected_high, expected_low])\n",
    "    chi_value = chisquare(observed, expected)\n",
    "    chi_squared.append(chi_value)\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c7f78-602c-47bc-8648-e793bac7bc55",
   "metadata": {},
   "source": [
    "Above we can see the results of chi-squared text for 10 terms. None of these 10 terms are statistically significant, because their `pvalue` is over 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570f133-6acf-4e33-a921-53d6a61dd684",
   "metadata": {},
   "source": [
    "## Applying the Chi-squared Test for Higher Frequency Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20af252-56ce-4cf1-908a-ae9ca9cd5a01",
   "metadata": {},
   "source": [
    "We can't really use our test for all the terms, because there are over 68997 terms, and running the code takes too long. Because of this, we will do chi-squared test for terms that have higher frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47db5b74-8276-4d95-b584-e0e3bd899403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939591\n"
     ]
    }
   ],
   "source": [
    "#instead of set let's make a list of all words\n",
    "word_list = []\n",
    "for index, row in data.iterrows():\n",
    "    split_question = row['clean_question'].split(\" \")\n",
    "    ### remove words with less than 6 characters\n",
    "    split_question = [word for word in split_question if len(word) > 5]\n",
    "    match_count = 0\n",
    "    #instead of checking is the world already in a set, let's just add it to a list\n",
    "    for word in split_question:\n",
    "        word_list.append(word)\n",
    "print(len(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b3b5f-6e74-4991-a674-a8f5fab6057e",
   "metadata": {},
   "source": [
    "We now have a list of almost a million words. Let's only choose 10 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03126595-1e84-4b73-8cbc-70dc2b0b13cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['archive', 'target', '_blank', 'country', 'called', 'president', 'american', 'became', 'played', 'before']\n"
     ]
    }
   ],
   "source": [
    "word_counts = {}\n",
    "for word in word_list:\n",
    "    if word in word_counts:\n",
    "        word_counts[word] += 1\n",
    "    else:\n",
    "        word_counts[word] = 1\n",
    "\n",
    "#filter words that appear less than 10 times\n",
    "sorted_words = sorted(word_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "top_10_words = sorted_words[:10]\n",
    "\n",
    "top_10_words_list = [word for word, count in top_10_words]\n",
    "print(top_10_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3bc7ee-3d2c-48cc-8b5a-75ae42ba8f21",
   "metadata": {},
   "source": [
    "Now we have 10 most frequently used words. Let's apply Chi-squared test for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d906d374-9538-4e33-b0bf-b13299c9cc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4732, 5802),\n",
       " (3885, 4614),\n",
       " (3864, 4570),\n",
       " (1647, 4332),\n",
       " (1700, 3721),\n",
       " (883, 2297),\n",
       " (1053, 2115),\n",
       " (903, 2230),\n",
       " (751, 2178),\n",
       " (787, 2114)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected = []\n",
    "for word in top_10_words_list:\n",
    "    term_counts =term_counter(word)\n",
    "    observed_expected.append(term_counts)\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdd4978c-acd4-4c7e-8e19-59cd8eb8f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive: pvalue: 0.0\n",
      "target: pvalue: 1.4383186286040423e-277\n",
      "_blank: pvalue: 1.0207344253417881e-278\n",
      "country: pvalue: 0.18758212679269265\n",
      "called: pvalue: 6.462707834956508e-07\n",
      "president: pvalue: 0.49362469359699845\n",
      "american: pvalue: 7.6417470118628e-10\n",
      "became: pvalue: 0.5279394222257846\n",
      "played: pvalue: 0.0013169445415356527\n",
      "before: pvalue: 0.15635593921158333\n"
     ]
    }
   ],
   "source": [
    "chi_squared = []\n",
    "p_values = []\n",
    "for list in observed_expected:\n",
    "    total = list[0] + list[1]\n",
    "    total_prop = total/data.shape[0]\n",
    "    expected_high = total_prop*high_value_count\n",
    "    expected_low = total_prop*low_value_count\n",
    "\n",
    "    observed = np.array([list[0], list[1]])\n",
    "    expected = np.array([expected_high, expected_low])\n",
    "    chi_value, p_value = chisquare(observed, expected)\n",
    "    chi_squared.append(chi_value)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "for word, p in zip(top_10_words_list, p_values):\n",
    "    print(f\"{word}: pvalue: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765b27b-2456-4176-839c-b4f9412921f9",
   "metadata": {},
   "source": [
    "## Statistically Significant Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024d1a8-def6-4634-935b-f95980bd02e2",
   "metadata": {},
   "source": [
    "Above we can see that from the top 10 words used, there are multiple words with p-values less than 0.05. This means that the following words are statistically significant:\n",
    "- `archive`\n",
    "- `target`\n",
    "- `_blank` (this probably means questions like \"The capital of Finland is _blank\")\n",
    "- `called`\n",
    "- `american`\n",
    "- `played`\n",
    "\n",
    "We only used top 10 words because even with 10 words, this code takes some time to perform. However, we could use this approach for many more words to find out which ones are statistically significant.\n",
    "\n",
    "Statistically significant words mean that they are very common in Jeopardy questions. It could be beneficial to study for questions that contain the following words. Especially if one is studying old questions, they probably should pay extra attention to questions that contain the word `archive`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
